---
title: "OCR workflows"
subtitle: "Critical view to current practices"
author: "Niko Partanen"
date: "2017/03/16"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false

---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```



background-image: url(images/inel_logo.png)

???


---
class: inverse, center, middle

# Basics of INEL workflow

---

## Texts

- Mainly published and printed Dolgan transcriptions
- Large amount of handwritten documents -- not covered here

## Tools

- We have been using ABBYY Finereader
- First goal is to bring texts into FLEx with metadata
    - Toolbox file as interchange format
- After annotations are completed in EXMARaLDA, the audio is aligned
- Git is used as version control across work phases

---
class: inverse, center, middle

# Paradox with ABBYY

---

## Desktop version

- Good user interface
- Training new models easy, although not transparent
- Practical to do fast post-correction after OCR
- **No XML export**

## Engine version

- Used from command line
- Only pre-defined models
- Cannot be post-corrected in Abbyy Desktop
- Good ALTO XML export

--

### How is this possible?

---

### How is this possible?

- In defence of ABBYY, other OCR tools suffer with same
- Maybe it simply is difficult to manage user edits and coordinates?

---

class: inverse, center, middle

# Currently lost information

---

## In book

- Coordinate information on page
- Some formatting
- Footnotes are later added manually as notes

---

class: inverse, center, middle

# Future tasks

---

## Combining text and coordinates

- Text files are nicely corrected
- XML files contain coordinate info
    - It must be possible to do matching between these two files?

## Combining corpora for research purposes

- Same speakers and writers
- Transcription system closely related to the orthography


- Written data so large that many NLP tools become available
- Spoken data enough closely related that reuse possible


<!--
---

class: inverse, center, middle
 
# Glimpse to handwritten text recognition

---

background-image: url(0001.jpg)

---

## State of the art

- Not yet used in INEL


- Current tools demand 50-100 pages of training data
    - Compare to the average size of one dataset
    
    
- Models are additive, so different handwritings help one another
    - Not tested yet, but probably more character set then language specific
    - Training a model for Scientific Komi Transcription a worthy goal
    
    
- Some tools proprietary, open source lags bit behind
    - Training data naturally free and can be reused
-->    
## Examples from difficulties

- Reconstructing paragraphs reliably from plain text very unreliable
- Distinguishing different numberings from one another also hard
- No chances to deal with more complex layout in the document
